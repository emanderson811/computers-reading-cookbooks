---
layout: page
title: OCR-ing the First 25
date: 2024-10-24
tags: recipes
author: Erin
excerpt: OCR and text pre-processing steps for the first 25 scanned cookbooks
---
## Selecting an OCR Engine
It will take a little over a semester for all 200 cookbooks to be scanned, so I decided to take the first 25 books scanned so far and test out my OCR and text pre-processing steps on them. This will allow me to see whether I have correctly planned the steps I’ll need to take with the full corpus to get meaningful results. 
Going into the project I had experience with and access to Tesseract OCR, an open-source commend line tool for converting images to machine-readable text, so I decided I would use that to create the .txt files I’ll need for analysis. When I first decided to use Tesseract I had tested a few scanned cookbooks and noticed that Tesseract struggled to recognize the fractions in ingredient lists, but otherwise seemed to do a pretty accurate job of handling the rest of the text. 

My colleague in Preservation who is managing digitization is also OCR-ing the texts as part of the digitization workflow we are testing for all digital collections. She is using ABBYY Finereader, a paid license product with a GUI. Since we’re using both products for different parts of the workflow and we have 25 completed, I now have more examples to compare to see if there is a significant difference in accuracy. With more examples to compare, I can now see a noticeable difference in how Tesseract and Finereader handle the table of contents and other non-standard text layouts as well as images and other “noise” on the page. 

{% include figure.html img="assets\tesseract-finereader-side.jpg" alt="comparison of ocr text files side by side" caption="Example of Tesseract OCR on left and ABBYY Finereader on right" %}

## Determining Pre-Processing Steps

